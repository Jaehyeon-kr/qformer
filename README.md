# ğŸ“š BLIP Q-Former Tutorial


![Q-Former Architecture]qformer_archi.png)

## ì†Œê°œ
ì´ í”„ë¡œì íŠ¸ëŠ” **BLIP (Bootstrapping Language-Image Pretraining)** ëª¨ë¸ì˜ í•µì‹¬ ëª¨ë“ˆì¸  
**Q-Former (Query Transformer)** í•™ìŠµ ë° ì‹¤í—˜ì„ ìœ„í•œ ì½”ë“œ ë² ì´ìŠ¤ì…ë‹ˆë‹¤.  

Q-FormerëŠ” **ì´ë¯¸ì§€ ì¸ì½”ë”(ViT ë“±)**ì—ì„œ ì¶”ì¶œí•œ ì‹œê°ì  í† í°ë“¤ì„  
**í•™ìŠµ ê°€ëŠ¥í•œ Query Token**ê³¼ êµì°¨ ì–´í…ì…˜(cross-attention)ì„ í†µí•´ ê²°í•©í•˜ì—¬,  
í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ì˜ í‘œí˜„ ê³µê°„ì„ íš¨ê³¼ì ìœ¼ë¡œ ì •ë ¬(alignment)í•©ë‹ˆë‹¤.

---

## ì•„í‚¤í…ì²˜


ì´ë¯¸ì§€ (ViT) â”€â–¶ ë¹„ì£¼ì–¼ í”¼ì³ â”€â”
â”‚
Query Token â”€â”€â”¼â”€â”€â–¶ Q-Former (BERT-like Transformer)
â”‚
í…ìŠ¤íŠ¸ (Tokenizer) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


- **ì´ë¯¸ì§€ ì¸ì½”ë”**: `ViT-B/16`, `EVA-CLIP`, `SigLIP` ë“± ì‚¬ìš© ê°€ëŠ¥  
- **Q-Former**: BERT êµ¬ì¡° ê¸°ë°˜, Self-Attention + Cross-Attention ë ˆì´ì–´ í¬í•¨  
- **í…ìŠ¤íŠ¸ ì¸ì½”ë”**: HuggingFace `BERT`/`RoBERTa`/`T5` ë“± í™•ì¥ ê°€ëŠ¥  

---
## ğŸ“œ ì°¸ê³  ë…¼ë¬¸

BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation (Li et al., 2022)

BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models (Li et al., 2023)

SEED-X: Multimodal Models with Unified Multi-granularity Comprehension and Generation
